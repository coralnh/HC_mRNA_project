{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from bioio import BioImage\n",
    "import bioio_ome_tiff #using TIFF not czi files\n",
    "from bioio_ome_tiff import Reader as OME_TIFFReader\n",
    "\n",
    "\n",
    "\n",
    "from bioio import BioImage\n",
    "import bioio_ome_tiff #using TIFF not czi files\n",
    "from bioio_ome_tiff import Reader as OME_TIFFReader\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from natsort import natsorted\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.signal as signal\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from scipy.stats import shapiro, levene\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import tifffile as tiff\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, rectangle\n",
    "\n",
    "from skimage.filters import threshold_otsu, median\n",
    "from skimage.morphology import disk, remove_small_objects\n",
    "\n",
    "import time\n",
    "import re\n",
    "import tifffile as tiff\n",
    "from pathlib import Path\n",
    "from bioio_ome_tiff import Reader as OME_TIFFReader\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#PART 1: fix all file names to make sure they all match, drop all files without a image pair. This isn't necessary if file naming is consistent.",
   "id": "27b0d316b3aedddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Fixing file name, function\n",
    "def fix_exp(exp_data: Path, exp_tiff_data: Path):\n",
    "    exp_tiff_data.mkdir(parents=True, exist_ok=True)           #make new file for .tif files\n",
    "    for file in exp_data.rglob(\"*.tif\"):\n",
    "        match = re.search(r'(\\d+pg)', file.name.lower())\n",
    "        if match and match.group(1) == '0pg':                #skip the 0pg images\n",
    "            print(f\"skipping {file.name} only 0pg\")\n",
    "            continue\n",
    "\n",
    "        new_name = file.name\n",
    "        new_name = new_name.replace(\"26-\", \"25-\")            #fixing misprint on date of 2026 to 2025\n",
    "        new_name = new_name.replace(\"400pg\", \"480pg\")        #fixing misprint on pg of 400 to 480\n",
    "\n",
    "        corrected_path = exp_tiff_data / new_name\n",
    "\n",
    "        try:                                                #list which files got their name corrected and add them to the new folder\n",
    "            img = tiff.imread(file)\n",
    "            tiff.imwrite(corrected_path, img)\n",
    "\n",
    "            if new_name != file.name:\n",
    "                print(f\"Renamed and saved: {file.name} → {corrected_path.name}\")\n",
    "            else:\n",
    "                print(f\"No renaming needed for: {file.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save {file.name} to {corrected_path.name}: {e}\")\n",
    "    print(f\"done\")\n",
    "    return(exp_tiff_data)"
   ],
   "id": "7c6785bbf76d0b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Using the above function of the HJ mRNA\n",
    "#HJ\n",
    "#give path to files\n",
    "HJ_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HJ_control')\n",
    "HJ_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HJ_TIFF')\n",
    "\n",
    "#run function\n",
    "fix_exp(HJ_data, HJ_tiff_data)\n"
   ],
   "id": "e9dd54d084801e14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Using the above function of the HC2 mRNA\n",
    "#HC2\n",
    "#give the path to the files\n",
    "HC2_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-2')\n",
    "HC2_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-2_TIFF')\n",
    "\n",
    "#run function\n",
    "fix_exp(HC2_data, HC2_tiff_data)"
   ],
   "id": "99178fa0f0635772"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Using the above function of the HC3 mRNA\n",
    "#HC3\n",
    "#give path to files\n",
    "HC3_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-3')\n",
    "HC3_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-3_TIFF')\n",
    "#run function\n",
    "fix_exp(HC3_data, HC3_tiff_data)"
   ],
   "id": "256b8d1d45b616eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Using the above function of the HC4 mRNA\n",
    "#HC4\n",
    "#give path to files\n",
    "HC4_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-4_Nov')\n",
    "HC4_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-4_TIFF')\n",
    "\n",
    "#run function\n",
    "fix_exp(HC4_data, HC4_tiff_data)"
   ],
   "id": "bf1434d6c930332c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Using the above function of the HC6 mRNA\n",
    "#HC6\n",
    "#give path to files\n",
    "HC6_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-6')\n",
    "HC6_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-6_TIFF')\n",
    "\n",
    "#run function\n",
    "fix_exp(HC6_data, HC6_tiff_data)"
   ],
   "id": "3332765bea368181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#PART 2: Uploading the blank background images for background subtraction.",
   "id": "64fb6697a430d0a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Getting images from path\n",
    "HC_data = Path('/Users/coral/Documents/data/HC_mRNA_October/HC_October_TIFFs')\n",
    "bg_files = [f for f in HC_data.rglob(\"*.tif\") if \"BLANK\" in f.name.upper()]    #my bg imgs have BLANK in the file, so find those and store them\n",
    "green_imgs = []\n",
    "red_imgs = []\n",
    "\n",
    "for file in bg_files:                      #Assign the background images 488 or 561 channel\n",
    "    reader = OME_TIFFReader(str(file))\n",
    "    img = reader.get_image_data(\"CYX\").astype(np.float32)\n",
    "    if \"488\" in file.name:\n",
    "        green_imgs.append(img)\n",
    "    elif \"561\" in file.name:\n",
    "        red_imgs.append(img)\n",
    "\n",
    "bg_green = np.squeeze(np.mean(np.stack(green_imgs, axis=0), axis=0).astype(np.float32) if green_imgs else np.nan)  #mean all the intensities of the bg img for each background\n",
    "bg_red = np.squeeze(np.mean(np.stack(red_imgs, axis=0), axis=0).astype(np.float32) if red_imgs else np.nan)\n",
    "\n",
    "\n",
    "print(f\"Background mean intensity - green:{bg_green}, red: {bg_red}\")"
   ],
   "id": "bd20c1b3a2a8ea83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part3: Making directories for each experimental condition",
   "id": "3aa048ee2be581b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_experiment(exp_name: str, tiff_dir: Path, date_to_day: dict):\n",
    "    \"\"\"\n",
    "    Process all TIFF images for an experiment to extract metadata such as\n",
    "    average pixel intensity, channel (green/red), pg level, and experimental day.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exp_name : str\n",
    "        Experiment name (e.g., \"HJ\")\n",
    "    tiff_dir : Path\n",
    "        Directory containing experiment TIFFs\n",
    "    date_to_day : dict\n",
    "        Mapping of dates to experimental days for this experiment\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Nested dictionary of metadata: {pg: {\"green\": [...], \"red\": [...]}}\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Processing experiment: {exp_name}\")\n",
    "    stack_dir = Path(tiff_dir)\n",
    "    exp_stk_img_metadata = {}\n",
    "\n",
    "    # Collect TIFFs\n",
    "    file_list = [f for f in stack_dir.iterdir() if f.suffix.lower() == \".tif\"]\n",
    "    print(f\"Found {len(file_list)} TIFFs in {stack_dir}\")\n",
    "\n",
    "    for idx, file in enumerate(file_list, start=1):\n",
    "        print(f\"\\n[{idx}/{len(file_list)}] Processing: {file.name}\", flush=True)\n",
    "\n",
    "        # Skip blanks/controls\n",
    "        if \"BLANK\" in file.name.upper():\n",
    "            print(f\"Skipping control/blank file: {file.name}\")\n",
    "            continue\n",
    "\n",
    "        # Extract pg (e.g., 120pg)\n",
    "        pg_parts = file.name.split(\"_\")\n",
    "        if len(pg_parts) < 3:\n",
    "            print(f\"Skipping file with unexpected name: {file.name}\")\n",
    "            continue\n",
    "        pg = pg_parts[2]\n",
    "\n",
    "        # Initialize structure for each pg\n",
    "        if pg not in exp_stk_img_metadata:\n",
    "            exp_stk_img_metadata[pg] = {\"green\": [], \"red\": []}\n",
    "\n",
    "        # Determine channel\n",
    "        if \"488\" in file.name:\n",
    "            channel = \"green\"\n",
    "        elif \"561\" in file.name:\n",
    "            channel = \"red\"\n",
    "        else:\n",
    "            print(f\"Skipping file (no valid channel): {file.name}\")\n",
    "            continue\n",
    "\n",
    "        # Determine experimental day\n",
    "        date_match = re.search(r\"(\\d{2}-\\d{2}-\\d{2})\", file.name)\n",
    "        date_str = date_match.group(1) if date_match else None\n",
    "        day = date_to_day.get(exp_name, {}).get(date_str, \"Unknown\")\n",
    "\n",
    "        # Load image safely\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            img_data = tiff.imread(file)\n",
    "            if img_data.ndim > 3:\n",
    "                raise ValueError(\"multi-dimensional TIFF, switching reader\")\n",
    "            img_data = np.squeeze(img_data).astype(np.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"tifffile failed, switching to OME_TIFFReader: {e}\")\n",
    "            try:\n",
    "                reader = OME_TIFFReader(str(file))\n",
    "                img_data = reader.get_image_data(\"CYX\", Z=0, T=0).astype(np.float32)\n",
    "                img_data = np.squeeze(img_data)\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to read {file.name}: {e2}\")\n",
    "                continue\n",
    "            finally:\n",
    "                reader = None\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"{file.name} loaded in {elapsed:.2f}s\")\n",
    "\n",
    "        # Compute average pixel intensity\n",
    "        img_mean = float(np.mean(img_data))\n",
    "\n",
    "        exp_stk_img_metadata[pg][channel].append({\n",
    "            \"file\": str(file),\n",
    "            \"exp\": exp_name,\n",
    "            \"day\": day,\n",
    "            \"avg_intensity\": img_mean\n",
    "        })\n",
    "\n",
    "        del img_data\n",
    "        gc.collect()\n",
    "\n",
    "    # Optional rename: normalize naming (e.g., 400pg → 480pg)\n",
    "    cleaned_metadata = {}\n",
    "    for pg, channels in exp_stk_img_metadata.items():\n",
    "        new_pg = pg.replace(\"400pg\", \"480pg\")\n",
    "        cleaned_metadata[new_pg] = channels\n",
    "\n",
    "    print(f\"Done processing {len(file_list)} files for {exp_name}.\")\n",
    "    return cleaned_metadata\n"
   ],
   "id": "6ae9478a9efbc336"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HJ directory\n",
    "#path to tiffs\n",
    "HJ_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HJ_TIFF')\n",
    "\n",
    "#date to day for HJ\n",
    "date_to_day = {\n",
    "    \"HJ\": {\n",
    "        \"25-10-06\": \"Day 1\",\n",
    "        \"25-10-07\": \"Day 2\",\n",
    "        \"25-10-08\": \"Day 3\",\n",
    "        \"25-10-09\": \"Day 4\",\n",
    "        \"25-10-10\": \"Day 5\"\n",
    "    }\n",
    "}\n",
    "#run function\n",
    "HJ_stk_img_metadata = process_experiment(\"HJ\", HJ_tiff_data, date_to_day)"
   ],
   "id": "68297cdbc0cbecaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC2 directory\n",
    "#path to tiffs\n",
    "HC2_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-2_TIFF')\n",
    "\n",
    "#date to day for HC2\n",
    "date_to_day = {\n",
    "    \"HC2\": {\n",
    "        \"25-10-14\": \"Day 1\",\n",
    "        \"25-10-15\": \"Day 2\",\n",
    "        \"25-10-16\": \"Day 3\",\n",
    "        \"25-10-17\": \"Day 4\",\n",
    "        \"25-10-18\": \"Day 5\"\n",
    "    }\n",
    "}\n",
    "#run function\n",
    "HC2_stk_img_metadata = process_experiment(\"HC2\", HC2_tiff_data, date_to_day)"
   ],
   "id": "ab113869617088e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC3 directory\n",
    "#path to tiffs\n",
    "HC3_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-3_TIFF')\n",
    "\n",
    "#date to day for HC3\n",
    "date_to_day = {\n",
    "    \"HC3\": {\n",
    "        \"25-10-21\": \"Day 1\",\n",
    "        \"25-10-22\": \"Day 2\",\n",
    "        \"25-10-23\": \"Day 3\",\n",
    "        \"25-10-24\": \"Day 4\",\n",
    "        \"25-10-25\": \"Day 5\"\n",
    "    }\n",
    "}\n",
    "#run function\n",
    "HC3_stk_img_metadata = process_experiment(\"HC3\", HC3_tiff_data, date_to_day)"
   ],
   "id": "ba21a4223686f0a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC4 directory\n",
    "#path to tiffs\n",
    "HC4_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-4_TIFF')\n",
    "\n",
    "#date to day for HC4\n",
    "date_to_day = {\n",
    "    \"HC4\": {\n",
    "        \"25-11-04\": \"Day 1\",\n",
    "        \"25-11-05\": \"Day 2\",\n",
    "        \"25-11-06\": \"Day 3\",\n",
    "        \"25-11-07\": \"Day 4\",\n",
    "        \"25-11-08\": \"Day 5\"\n",
    "    }\n",
    "}\n",
    "#run function\n",
    "HC4_stk_img_metadata = process_experiment(\"HC4\", HC4_tiff_data, date_to_day)"
   ],
   "id": "dfc87354a5681cde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC6 directory\n",
    "#path to tiffs\n",
    "HC6_tiff_data = Path('/Users/coral/Documents/data/HC_mRNA_October/October/HC-6_TIFF')\n",
    "\n",
    "#date to day for HC6\n",
    "date_to_day = {\n",
    "    \"HC6\": {\n",
    "        \"25-10-14\": \"Day 1\",\n",
    "        \"25-10-15\": \"Day 2\",\n",
    "        \"25-10-16\": \"Day 3\",\n",
    "        \"25-10-17\": \"Day 4\",\n",
    "        \"25-10-18\": \"Day 5\"\n",
    "    }\n",
    "}\n",
    "#run function\n",
    "HC6_stk_img_metadata = process_experiment(\"HC6\", HC6_tiff_data, date_to_day)"
   ],
   "id": "6ec8acbf173ad0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part4: Correcting images with Background subtraction and normalizing to 561",
   "id": "923641ad5063bd99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def correct_images(stk_img_metadata, bg_green, bg_red, output_dir, saturation_value=65535):\n",
    "    \"\"\"\n",
    "    Apply background correction, saturation masking, and compute average intensity\n",
    "    for all images in an experiment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stk_img_metadata : dict\n",
    "        Metadata structure {pg: {\"green\": [...], \"red\": [...]}}\n",
    "    bg_green : np.ndarray\n",
    "        Background image for green channel\n",
    "    bg_red : np.ndarray\n",
    "        Background image for red channel\n",
    "    output_dir : Path or str\n",
    "        Directory to save corrected images\n",
    "    saturation_value : int, optional\n",
    "        Saturation threshold (default 65535 for 16-bit images)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Updated metadata with corrected image file paths and avg_intensity\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for pg, channels in stk_img_metadata.items():\n",
    "        for channel, items in channels.items():\n",
    "            for i, item in enumerate(items):\n",
    "                file_path = Path(item[\"file\"])\n",
    "\n",
    "                # Load image\n",
    "                img = tiff.imread(file_path).astype(np.float32)\n",
    "\n",
    "                # Mask saturated pixels\n",
    "                img[img == saturation_value] = np.nan\n",
    "\n",
    "                # Background subtraction\n",
    "                if channel == \"green\":\n",
    "                    img = img - bg_green\n",
    "                elif channel == \"red\":\n",
    "                    img = img - bg_red\n",
    "\n",
    "                # Mask nonpositive values\n",
    "                img[img <= 0] = np.nan\n",
    "\n",
    "                # Save corrected image\n",
    "                corrected_file = output_dir / f\"{pg}_{channel}_{i}_corrected.tif\"\n",
    "                tiff.imwrite(corrected_file, img.astype(np.float32))\n",
    "\n",
    "                # Update metadata\n",
    "                stk_img_metadata[pg][channel][i][\"file_corr\"] = str(corrected_file)\n",
    "                stk_img_metadata[pg][channel][i][\"avg_intensity\"] = float(np.nanmean(img))\n",
    "\n",
    "                del img\n",
    "                gc.collect()\n",
    "\n",
    "    print(\"✅ Correction and avg_intensity computation complete.\")\n",
    "    return stk_img_metadata\n",
    "\n",
    "\n",
    "def normalize_red_to_green(stk_img_metadata):\n",
    "    \"\"\"\n",
    "    Normalize red channel intensities relative to green channel for each pg.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stk_img_metadata : dict\n",
    "        Metadata structure {pg: {\"green\": [...], \"red\": [...]}} with avg_intensity fields\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Updated metadata with normalization factors and normalized file paths\n",
    "    \"\"\"\n",
    "    for pg, channels in stk_img_metadata.items():\n",
    "        green_items = channels.get(\"green\", [])\n",
    "        red_items = channels.get(\"red\", [])\n",
    "\n",
    "        print(f\"\\nNormalizing pg = {pg} | green: {len(green_items)} | red: {len(red_items)}\")\n",
    "\n",
    "        for i, red_item in enumerate(red_items):\n",
    "            if i >= len(green_items):\n",
    "                print(f\"Skipping red[{i}] — no matching green image.\")\n",
    "                continue\n",
    "\n",
    "            green_avg = green_items[i].get(\"avg_intensity\", np.nan)\n",
    "            red_avg = red_item.get(\"avg_intensity\", np.nan)\n",
    "\n",
    "            if np.isnan(green_avg) or green_avg == 0:\n",
    "                print(f\"Skipping pg={pg}, index={i}: invalid green_avg ({green_avg})\")\n",
    "                continue\n",
    "\n",
    "            norm_factor = red_avg / green_avg\n",
    "            red_item[\"norm_factor\"] = norm_factor\n",
    "\n",
    "            if np.isnan(norm_factor) or norm_factor == 0:\n",
    "                print(f\"Skipping pg={pg}, index={i}: invalid norm_factor ({norm_factor})\")\n",
    "                continue\n",
    "\n",
    "            red_file_corr = red_item.get(\"file_corr\", None)\n",
    "            if red_file_corr:\n",
    "                img_red = tiff.imread(red_file_corr).astype(np.float32)\n",
    "                img_red_norm = img_red / norm_factor\n",
    "\n",
    "                norm_file = Path(red_file_corr).with_name(\n",
    "                    f\"{Path(red_file_corr).stem}_norm.tif\"\n",
    "                )\n",
    "                tiff.imwrite(norm_file, img_red_norm.astype(np.float32))\n",
    "                red_item[\"file_norm\"] = str(norm_file)\n",
    "\n",
    "                del img_red, img_red_norm\n",
    "                gc.collect()\n",
    "\n",
    "        print(f\"Done with {pg}\")\n",
    "\n",
    "    print(\"Red/green normalization complete.\")\n",
    "    return stk_img_metadata\n"
   ],
   "id": "656dca51490d79b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HJ_corrected_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/October/HJ_corr\")\n",
    "HJ_stk_img_metadata = correct_images(\n",
    "    stk_img_metadata=HJ_stk_img_metadata,\n",
    "    bg_green=bg_green,\n",
    "    bg_red=bg_red,\n",
    "    output_dir=HJ_corrected_dir\n",
    ")\n",
    "\n",
    "HJ_stk_img_metadata = normalize_red_to_green(HJ_stk_img_metadata)\n"
   ],
   "id": "f2b9c75025c15f00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HC2_corrected_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/October/HC2_corr\")\n",
    "HC2_stk_img_metadata = correct_images(\n",
    "    stk_img_metadata=HC2_stk_img_metadata,\n",
    "    bg_green=bg_green,\n",
    "    bg_red=bg_red,\n",
    "    output_dir=HC2_corrected_dir\n",
    ")\n",
    "\n",
    "HC2_stk_img_metadata = normalize_red_to_green(HC2_stk_img_metadata)\n"
   ],
   "id": "42dc5276765c0a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HC3_corrected_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/October/HC3_corr\")\n",
    "HC3_stk_img_metadata = correct_images(\n",
    "    stk_img_metadata=HC3_stk_img_metadata,\n",
    "    bg_green=bg_green,\n",
    "    bg_red=bg_red,\n",
    "    output_dir=HC3_corrected_dir\n",
    ")\n",
    "\n",
    "HC3_stk_img_metadata = normalize_red_to_green(HC3_stk_img_metadata)\n"
   ],
   "id": "d1048a9d35346ae5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HC4_corrected_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/October/HC4_corr\")\n",
    "HC4_stk_img_metadata = correct_images(\n",
    "    stk_img_metadata=HC4_stk_img_metadata,\n",
    "    bg_green=bg_green,\n",
    "    bg_red=bg_red,\n",
    "    output_dir=HC4_corrected_dir\n",
    ")\n",
    "\n",
    "HC4_stk_img_metadata = normalize_red_to_green(HC4_stk_img_metadata)\n"
   ],
   "id": "cd9439f25a8bbedc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HC6_corrected_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/October/HC6_corr\")\n",
    "HC6_stk_img_metadata = correct_images(\n",
    "    stk_img_metadata=HC6_stk_img_metadata,\n",
    "    bg_green=bg_green,\n",
    "    bg_red=bg_red,\n",
    "    output_dir=HC6_corrected_dir\n",
    ")\n",
    "\n",
    "HC6_stk_img_metadata = normalize_red_to_green(HC6_stk_img_metadata)\n"
   ],
   "id": "bc0249c2b80c1e6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part5: Build Dataframe for each condition",
   "id": "3417369cc2d4ae9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_avg_norm_df(stk_img_metadata, exp_name):\n",
    "    rows = []\n",
    "    for pg, channels in stk_img_metadata.items():\n",
    "        red_items = channels.get(\"red\", [])\n",
    "        for item in red_items:\n",
    "            avg_norm = item.get(\"avg_intensity\", np.nan)  # use already stored value\n",
    "            day = item.get(\"day\", \"Unknown\")\n",
    "            rows.append({\n",
    "                \"exp\": exp_name,\n",
    "                \"pg\": pg,\n",
    "                \"day\": day,\n",
    "                \"avg_norm_intensity\": avg_norm\n",
    "            })\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"✅ DataFrame built for {exp_name} ({len(df)} entries).\")\n",
    "    return df\n"
   ],
   "id": "dcd1aca1a40ee575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HJ dataframe\n",
    "df_HJ = build_avg_norm_df(HJ_stk_img_metadata, \"HJ\")\n",
    "df_HJ.head()"
   ],
   "id": "6e6d62152137d98f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC2 dataframe\n",
    "df_HC2 = build_avg_norm_df(HC2_stk_img_metadata, \"HC2\")\n",
    "df_HC2.head()"
   ],
   "id": "853a7de6b67535fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC3 dataframe\n",
    "df_HC3 = build_avg_norm_df(HC3_stk_img_metadata, \"HC3\")\n",
    "df_HC3.head()"
   ],
   "id": "e865f96e1038765f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC4 dataframe\n",
    "df_HC4 = build_avg_norm_df(HC4_stk_img_metadata, \"HC4\")\n",
    "df_HC4.head()"
   ],
   "id": "fd3ffca132ea8e75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#HC6 dataframe\n",
    "df_HC6 = build_avg_norm_df(HC6_stk_img_metadata, \"HC6\")\n",
    "df_HC6.head()"
   ],
   "id": "b65273a2c39e789e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part6: Combine all the dataframe for plotting and fold change",
   "id": "27a2835ccf8e14cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine all experiment DataFrames\n",
    "all_exps = {\n",
    "    \"HJ\": df_HJ,\n",
    "    \"HC2\": df_HC2,\n",
    "    \"HC3\": df_HC3,\n",
    "    \"HC4\": df_HC4,\n",
    "    \"HC6\": df_HC6,\n",
    "}\n",
    "\n",
    "# Combine all into one big DataFrame with an experiment column\n",
    "combined_df = pd.concat(\n",
    "    [df.assign(experiment=name) for name, df in all_exps.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Keep consistent experiment color palette\n",
    "exp_palette = dict(zip(all_exps.keys(), sns.color_palette(\"tab10\", n_colors=len(all_exps))))\n"
   ],
   "id": "1e264d33ccd36a4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part7: Getting the average baseline of the control ( 120pg HJ) for Fold change analysis",
   "id": "592dc3de0b0f85f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#120 baseline\n",
    "import pandas as pd\n",
    "\n",
    "# --- Baseline: get HJ averages per pg & day ---\n",
    "baseline_HJ_120 = (\n",
    "    combined_df[\n",
    "        (combined_df[\"experiment\"] == \"HJ\") & (combined_df[\"pg\"] == \"120pg\")\n",
    "    ]\n",
    "    .groupby([\"day\"], as_index=False)[\"avg_norm_intensity\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"avg_norm_intensity\": \"HJ_120pg_intensity\"})\n",
    ")\n",
    "\n",
    "# --- Merge HJ baseline back onto the combined data ---\n",
    "merged = combined_df.merge(baseline_HJ_120, on=[\"day\"], how=\"left\")\n",
    "\n",
    "# --- Compute fold change relative to HJ ---\n",
    "merged[\"fold_change_v_120pg\"] = merged[\"avg_norm_intensity\"] / merged[\"HJ_120pg_intensity\"]\n",
    "\n",
    "# --- Filter for only HC2 and HC6 (the comparisons you care about) ---\n",
    "fc_df_v_HJ_120pg = merged[merged[\"experiment\"].isin([\"HC2\", \"HC3\",\"HC4\",\"HC6\"])]\n",
    "\n",
    "# Optional: sanity check\n",
    "print(fc_df_v_HJ_120pg[[\"experiment\", \"pg\", \"day\", \"avg_norm_intensity\", \"HJ_120pg_intensity\", \"fold_change_v_120pg\"]].head())\n"
   ],
   "id": "f1a0a9e51c0bffaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part8: Plotting the fold change of each condition to 120 pg of HJ",
   "id": "a7eb24868e174a85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#fold change to HJ 120\n",
    "fc_df_v_HJ_120pg = fc_df_v_HJ_120pg.copy()\n",
    "experiment_order = [\"HC6\",\"HC2\",\"HC3\",\"HC4\"]\n",
    "palette = {\n",
    "    \"HC2\": \"#2ecc71\",\n",
    "    \"HC6\": \"#3498db\",\n",
    "    \"HC4\": \"#ff0000\",\n",
    "    \"HC3\": \"#ffa500\",\n",
    "}\n",
    "# Normalize day strings and extract numeric day (works if day values are \"1\", \"Day 1\", \"day_1\", \"day1\", etc.)\n",
    "fc_df_v_HJ_120pg[\"day_str\"] = fc_df_v_HJ_120pg[\"day\"].astype(str).str.strip().str.title().str.replace(\"_\", \" \")\n",
    "fc_df_v_HJ_120pg[\"day_num\"] = fc_df_v_HJ_120pg[\"day_str\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Sort by numeric day so lines draw in correct order\n",
    "fc_df_v_HJ_120pg = fc_df_v_HJ_120pg.sort_values(\"day_num\")\n",
    "\n",
    "# Plot with numeric x, then set human-friendly xticks\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.lineplot(\n",
    "    data=fc_df_v_HJ_120pg,\n",
    "    x=\"day_num\",           # numeric ordering\n",
    "    y=\"fold_change_v_120pg\",\n",
    "    hue=\"experiment\",\n",
    "    hue_order=experiment_order,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "plt.axhline(1, color=\"gray\", linestyle=\"--\", label=\"HJ baseline\")\n",
    "plt.xticks([1,2,3,4,5], [\"Day 1\",\"Day 2\",\"Day 3\",\"Day 4\",\"Day 5\"])\n",
    "plt.xlim(0.8, 5.2)  # small padding\n",
    "plt.ylim(0,12)\n",
    "plt.ylabel(\"Fold Change (vs HJ)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Fold Change of HC Experiments Relative to HJ 120pg Over Time\")\n",
    "plt.legend(title=\"Experiment\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/coral/Documents/data/HC_mRNA_October/11-09-25_graphs_pg/fold_change_plot_HJ120.pdf\")\n",
    "plt.show()\n"
   ],
   "id": "3a9ec83ebcaf658a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Plotting the fold change of the best conditions, HC2 and HC6.\n",
    "fc_df_HC2_HC6_v_HJ_120 = fc_df_v_HJ_120pg[fc_df_v_HJ_120pg[\"experiment\"].isin([\"HC2\", \"HC6\"])].copy()\n",
    "\n",
    "\n",
    "# Normalize day strings and extract numeric day (works if day values are \"1\", \"Day 1\", \"day_1\", \"day1\", etc.)\n",
    "fc_df_HC2_HC6_v_HJ_120[\"day_str\"] = fc_df_HC2_HC6_v_HJ_120[\"day\"].astype(str).str.strip().str.title().str.replace(\"_\", \" \")\n",
    "fc_df_HC2_HC6_v_HJ_120[\"day_num\"] = fc_df_HC2_HC6_v_HJ_120[\"day_str\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Sort by numeric day so lines draw in correct order\n",
    "fc_df_HC2_HC6_v_HJ_120 = fc_df_HC2_HC6_v_HJ_120.sort_values(\"day_num\")\n",
    "palette = {\n",
    "    \"HC2\": \"#2ecc71\",\n",
    "    \"HC6\": \"#3498db\"\n",
    "}\n",
    "# Plot with numeric x, then set human-friendly xticks\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.lineplot(\n",
    "    data=fc_df_HC2_HC6_v_HJ_120,\n",
    "    x=\"day_num\",           # numeric ordering\n",
    "    y=\"fold_change_v_120pg\",\n",
    "    hue=\"experiment\",\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "plt.axhline(1, color=\"gray\", linestyle=\"--\", label=\"HJ baseline\")\n",
    "plt.xticks([1,2,3,4,5], [\"Day 1\",\"Day 2\",\"Day 3\",\"Day 4\",\"Day 5\"])\n",
    "plt.xlim(0.8, 5.2)  # small padding\n",
    "plt.ylim(0,12)\n",
    "plt.ylabel(\"Fold Change (vs HJ)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Fold Change of HC2 and HC6 Relative to HJ 120pg Over Time\")\n",
    "plt.legend(title=\"Experiment\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/coral/Documents/data/HC_mRNA_October/11-09-25_graphs_pg/HC2_HC6_fold_change_HJ120.pdf\")\n",
    "plt.show()\n"
   ],
   "id": "af2e50e82597169a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Fold change of HC2 and HC6 only at 480 pg.\n",
    "fc_df_HC2_HC6_v_HJ_120 = fc_df_v_HJ_120pg[fc_df_v_HJ_120pg[\"experiment\"].isin([\"HC2\", \"HC6\"])].copy()\n",
    "#filtering\n",
    "fc_df_HC2_HC6_v_HJ_120 = fc_df_HC2_HC6_v_HJ_120[\n",
    "    fc_df_HC2_HC6_v_HJ_120[\"pg\"] == \"480pg\"\n",
    "].copy()\n",
    "\n",
    "\n",
    "# Normalize day strings and extract numeric day (works if day values are \"1\", \"Day 1\", \"day_1\", \"day1\", etc.)\n",
    "fc_df_HC2_HC6_v_HJ_120[\"day_str\"] = fc_df_HC2_HC6_v_HJ_120[\"day\"].astype(str).str.strip().str.title().str.replace(\"_\", \" \")\n",
    "fc_df_HC2_HC6_v_HJ_120[\"day_num\"] = fc_df_HC2_HC6_v_HJ_120[\"day_str\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "# Sort by numeric day so lines draw in correct order\n",
    "fc_df_HC2_HC6_v_HJ_120 = fc_df_HC2_HC6_v_HJ_120.sort_values(\"day_num\")\n",
    "palette = {\n",
    "    \"HC2\": \"#2ecc71\",\n",
    "    \"HC6\": \"#3498db\"\n",
    "}\n",
    "# Plot with numeric x, then set human-friendly xticks\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.lineplot(\n",
    "    data=fc_df_HC2_HC6_v_HJ_120,\n",
    "    x=\"day_num\",           # numeric ordering\n",
    "    y=\"fold_change_v_120pg\",\n",
    "    hue=\"experiment\",\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "plt.axhline(1, color=\"gray\", linestyle=\"--\", label=\"HJ baseline\")\n",
    "plt.xticks([1,2,3,4,5], [\"Day 1\",\"Day 2\",\"Day 3\",\"Day 4\",\"Day 5\"])\n",
    "plt.xlim(0.8, 5.2)  # small padding\n",
    "plt.ylim(0,12)\n",
    "plt.ylabel(\"Fold Change (vs HJ)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Fold Change of HC2 and HC6 480 pg Relative to HJ 120pg Over Time\")\n",
    "plt.legend(title=\"Experiment\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/coral/Documents/data/HC_mRNA_October/11-09-25_graphs_pg/HC2_HC6_480_fold_change_HJ120.pdf\")\n",
    "plt.show()\n"
   ],
   "id": "c8084411a15c2555"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Part9: Plotting the Death and abnormalty of the injection conditions",
   "id": "4a6974d1b88e2658"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 1. Load the CSV ---\n",
    "file_path = '/Users/coral/Documents/data/HC_mRNA_October/HC_mRNA_Death - wout_imaged.csv'  # update path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2. Preview structure (optional) ---\n",
    "print(df.columns)\n",
    "\n",
    "\n",
    "# --- 3. Combine totals ---\n",
    "df[\"Total_Dead\"] = df[\"day_1_death\"] + df[\"day_2_death\"]\n",
    "df[\"Total_Abnormal\"] = df[\"day_1_ab\"] + df[\"day_2_ab\"]\n",
    "\n",
    "# --- 4. Compute percentages ---\n",
    "df[\"% Dead\"] = (df[\"Total_Dead\"] / df[\"total_wout_imaged\"]) * 100\n",
    "df[\"% Abnormal\"] = (df[\"Total_Abnormal\"] / df[\"total_wout_imaged\"]) * 100\n",
    "\n",
    "\n",
    "# --- 5. Calculate \"Normal\" as what's left to reach 100% ---\n",
    "df[\"% Normal\"] = 100 - (df[\"% Dead\"] + df[\"% Abnormal\"])\n",
    "\n",
    "df[\"exp_pg\"] = df[\"exp\"].astype(str) + \"_\" + df[\"pg\"].astype(str)\n",
    "\n",
    "# --- 6. Prepare for plotting ---\n",
    "plot_df = df[[\"exp_pg\", \"% Dead\", \"% Abnormal\", \"% Normal\"]]\n",
    "plot_df = plot_df.set_index(\"exp_pg\")\n",
    "\n",
    "save_dir = Path(\"/Users/coral/Documents/data/HC_mRNA_October/bar_graphs\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 7. Plot stacked bar chart ---\n",
    "colors = [\"#e74c3c\", \"#f39c12\", \"#2ecc71\"]  # red, orange, blue, green\n",
    "\n",
    "plot_df.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=colors,\n",
    "    edgecolor=\"black\",\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "plt.ylabel(\"% of Embryos\")\n",
    "plt.xlabel(\"exp + pg\")\n",
    "plt.title(\"Embryo Outcomes per Condition without Imaged Embryos\")\n",
    "plt.ylim(0, 100)\n",
    "plt.legend(title=\"Outcome\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "save_path_png = save_dir / \"Embryo_Outcomes_without_Imaged.png\"\n",
    "save_path_pdf = save_dir / \"Embryo_Outcomes_without_Imaged.pdf\"\n",
    "\n",
    "plt.savefig(save_path_png, dpi=300)\n",
    "plt.savefig(save_path_pdf, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "eb33d49c6d463e27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
